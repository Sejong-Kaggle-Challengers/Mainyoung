{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "소설작가웩.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1RY99taHWZ0o",
        "outputId": "ff62ef6c-faef-4df4-f66f-399d8bb278b4"
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/dc/2bdc73a88a3661fdea62242e7e074e3e2b600f01543ce24751a48d486ad5/tf_nightly-2.5.0.dev20210304-cp37-cp37m-manylinux2010_x86_64.whl (410.0MB)\n",
            "\u001b[K     |████████████████████████████████| 410.0MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Collecting tb-nightly~=2.5.0.a\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/f4/72947db77318db93ac0d29ff02509c33cf4686784c4a2832e89724591694/tb_nightly-2.5.0a20210304-py3-none-any.whl (6.1MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Collecting grpcio~=1.34.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/d1/f38a91d8724706427fe973a7dfa11e938cee98aa7196b03d870a25a08bab/grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 45.4MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly~=2.5.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/14/85df3bc812c6dedcacacb17d8dc53a5155a554b577b4e2c5b6665bc6feb1/tf_estimator_nightly-2.5.0.dev2021030401-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tf-nightly) (54.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.27.0)\n",
            "Collecting tensorboard-data-server<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6f/a1a04f6aece9cdabe80fba01241e76172380753801e34ad50d482fbde0c0/tensorboard_data_server-0.3.0-py3-none-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.5.0.a->tf-nightly) (3.3.4)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.5.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.5.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.5.0.a->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.5.0.a->tf-nightly) (3.4.0)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: grpcio, tensorboard-data-server, tb-nightly, cached-property, h5py, gast, tf-estimator-nightly, tf-nightly\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 tb-nightly-2.5.0a20210304 tensorboard-data-server-0.3.0 tf-estimator-nightly-2.5.0.dev2021030401 tf-nightly-2.5.0.dev20210304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "grpc",
                  "h5py",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZvKSsx7_VZX",
        "outputId": "74d0870e-ee39-4d5e-8f5f-8406e63ef8f1"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTjFq6YR-yz0"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "author_dir = '/content/gdrive/MyDrive/캐글스터디/소설작가분류'\r\n",
        "train_dir = os.path.join(author_dir, 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_arkA_TbAWg8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "train =pd.read_csv('/content/gdrive/MyDrive/캐글스터디/소설작가분류/train.csv')\r\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/캐글스터디/소설작가분류/test_x.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXLC7YQtCXcX"
      },
      "source": [
        "#Data Preprocessing\r\n",
        "\r\n",
        "1. 데이터를 눈으로 확인하며 특수문자, 불용어, 문장구조에 대한 감을 잡는다.\r\n",
        "\r\n",
        "2. 불용어를 설정하고 리스트에 저장한다. \r\n",
        "\r\n",
        "3. 불용어 이외의 특수 문자들을 제거한다.(정규표현식 패키지(re)를 사용)\r\n",
        "\r\n",
        "4. 형태소 분석을 통해 문장을 형태소 단위의 토큰으로 분리.이때 내가 설정한 불용어들을 결과로 반환해주는 형태소 분석기를 사용 해야함. 예를 들어 조사를 불용어로 설정하였는데 조사를 분리해주지 못하는 형태소 분석기는 후보에서 제외하면 됨.\r\n",
        "\r\n",
        "5. 형태소 단위의 토큰들을 기반으로 리스트에 저장된 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "SwQCBeXTAyUH",
        "outputId": "f13cf28e-4e4f-488e-835a-2d9e74adca61"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>54874</td>\n",
              "      <td>“Is that you, Mr. Smith?” odin whispered. “I h...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54875</th>\n",
              "      <td>54875</td>\n",
              "      <td>I told my plan to the captain, and between us ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54876</th>\n",
              "      <td>54876</td>\n",
              "      <td>\"Your sincere well-wisher, friend, and sister...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54877</th>\n",
              "      <td>54877</td>\n",
              "      <td>“Then you wanted me to lend you money?”</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54878</th>\n",
              "      <td>54878</td>\n",
              "      <td>It certainly had not occurred to me before, bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54879 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                               text  author\n",
              "0          0  He was almost choking. There was so much, so m...       3\n",
              "1          1             “Your sister asked for it, I suppose?”       2\n",
              "2          2   She was engaged one day as she walked, in per...       1\n",
              "3          3  The captain was in the porch, keeping himself ...       4\n",
              "4          4  “Have mercy, gentlemen!” odin flung up his han...       3\n",
              "...      ...                                                ...     ...\n",
              "54874  54874  “Is that you, Mr. Smith?” odin whispered. “I h...       2\n",
              "54875  54875  I told my plan to the captain, and between us ...       4\n",
              "54876  54876   \"Your sincere well-wisher, friend, and sister...       1\n",
              "54877  54877            “Then you wanted me to lend you money?”       3\n",
              "54878  54878  It certainly had not occurred to me before, bu...       0\n",
              "\n",
              "[54879 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiDvJQuDBF6H",
        "outputId": "678f764d-bd9f-45b6-ed52-677bb2b23915"
      },
      "source": [
        "train['author'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 1, 4, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eu-LvWapMOa_",
        "outputId": "82686086-ce13-4f4f-d47f-45e31c7d5b72"
      },
      "source": [
        "X = train.drop('author', axis = 1)\r\n",
        "X = X.drop(labels='index',axis = 1)\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>“Is that you, Mr. Smith?” odin whispered. “I h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54875</th>\n",
              "      <td>I told my plan to the captain, and between us ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54876</th>\n",
              "      <td>\"Your sincere well-wisher, friend, and sister...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54877</th>\n",
              "      <td>“Then you wanted me to lend you money?”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54878</th>\n",
              "      <td>It certainly had not occurred to me before, bu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54879 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "0      He was almost choking. There was so much, so m...\n",
              "1                 “Your sister asked for it, I suppose?”\n",
              "2       She was engaged one day as she walked, in per...\n",
              "3      The captain was in the porch, keeping himself ...\n",
              "4      “Have mercy, gentlemen!” odin flung up his han...\n",
              "...                                                  ...\n",
              "54874  “Is that you, Mr. Smith?” odin whispered. “I h...\n",
              "54875  I told my plan to the captain, and between us ...\n",
              "54876   \"Your sincere well-wisher, friend, and sister...\n",
              "54877            “Then you wanted me to lend you money?”\n",
              "54878  It certainly had not occurred to me before, bu...\n",
              "\n",
              "[54879 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "L1TfD8rUMm8t",
        "outputId": "18b82c87-1756-44ce-9071-82054c391cdd"
      },
      "source": [
        "y = train.drop(labels='index',axis = 1)\r\n",
        "y = y.drop(labels='text',axis = 1)\r\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54875</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54876</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54877</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54878</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54879 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       author\n",
              "0           3\n",
              "1           2\n",
              "2           1\n",
              "3           4\n",
              "4           3\n",
              "...       ...\n",
              "54874       2\n",
              "54875       4\n",
              "54876       1\n",
              "54877       3\n",
              "54878       0\n",
              "\n",
              "[54879 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz-7DtOQNSSp"
      },
      "source": [
        "#데이터 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpmLf7o-ABsH",
        "outputId": "9a5d7bed-ce2c-4eb4-9b37-d94be2320834"
      },
      "source": [
        "from keras.preprocessing.text  import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "maxlen = 100 # 100개 이후 단어는 버림\r\n",
        "max_words = 107402\r\n",
        "\r\n",
        "token = Tokenizer()\r\n",
        "token.fit_on_texts(X['text'])\r\n",
        "sequences = token.texts_to_sequences(X['text'])\r\n",
        "\r\n",
        "word_index = token.word_index\r\n",
        "print('%s개의 고유한 토큰을 찾았습니다.' %len(word_index))\r\n",
        "\r\n",
        "data = pad_sequences(sequences,maxlen = maxlen)\r\n",
        "labels = np.asarray(y)\r\n",
        "print('데이터 텐서의 크기:', data.shape)\r\n",
        "print('레이블 텐서의 크기:', labels.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42330개의 고유한 토큰을 찾았습니다.\n",
            "데이터 텐서의 크기: (54879, 100)\n",
            "레이블 텐서의 크기: (54879, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAN6E2s_gHND",
        "outputId": "1fb3d06d-1d67-4cd8-815c-75aa32632750"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\r\n",
        "y= to_categorical(labels)\r\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iryotwOHEWO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test =train_test_split(data, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg3qJ0T_Hg6s"
      },
      "source": [
        "#GloVe 단어 임베딩 내려받기\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFhkrl0yHlfA",
        "outputId": "cfb3946d-b755-4f31-e6c7-b422229b7bfe"
      },
      "source": [
        "glove_dir = '/content/drive/MyDrive/캐글스터디/GloVe/'\r\n",
        "embeddings_index = {}\r\n",
        "f = open(os.path.join('/content/gdrive/MyDrive/캐글스터디/GloVe/glove.6B.300d.txt'), encoding='utf-8')\r\n",
        "for line in f:\r\n",
        "  values = line.split()\r\n",
        "  word = values[0]\r\n",
        "  coefs = np.asarray(values[1:], dtype = 'float32')\r\n",
        "  embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "print('%s개의 단어를 찾았습니다.' %len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107402개의 단어를 찾았습니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXr2683YiVX7"
      },
      "source": [
        "\r\n",
        "'''embedding_matrix = np.zeros((len(embeddings_index), 300)) #300차원의 임베딩 매트릭스 생성\r\n",
        "\r\n",
        "for index, word in enumerate(embeddings_index): #vocabulary에 있는 토큰들을 하나씩 넘겨줍니다.\r\n",
        "    if word in word_index: #넘겨 받은 토큰이 word2vec에 존재하면(이미 훈련이 된 토큰이라는 뜻)\r\n",
        "        embedding_vector = embeddings_index[word] #해당 토큰에 해당하는 vector를 불러오고\r\n",
        "        embedding_matrix[i] = embedding_vector #해당 위치의 embedding_mxtrix에 저장합니다.\r\n",
        "    else:\r\n",
        "        print(\"[0]glove 없는 단어입니다.\".format(index))\r\n",
        "        break\r\n",
        "        '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4gIBafXRbe3"
      },
      "source": [
        "embedding_dim = 300\r\n",
        "embedding_matrix= np.zeros((max_words, embedding_dim))\r\n",
        "for word, i in word_index.items():\r\n",
        "  if i < max_words:\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNsOZ9FLcr-Q",
        "outputId": "dc4ecd03-57c2-47c2-c669-26413309cc52"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107402, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUZhIMJNCmgP"
      },
      "source": [
        "#Model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZdA_2uOCqWH",
        "outputId": "785c92c7-a4b8-454b-db8d-eb574538efb4"
      },
      "source": [
        "from keras.models  import Sequential\r\n",
        "from keras.layers  import Embedding, Flatten, Dense,MaxPooling1D\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(max_words, embedding_dim, input_length= 100))  #https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\r\n",
        "                                                                      # Embedding layer에서는 Embedding(input_dim, output_dim을 기본으로 주입)\r\n",
        "                                                                      #Embedding 층은 크기가 (samples, sequence_length)인 2D 정수텐서를 입력으로 받는다.\r\n",
        "                                                                      # 배치에 있는 모든 시퀀스의 크기는 같아야 하므로 작은 길이의 시퀀스는 0으로 패딩되고 길이가 더 긴 시퀀스는 잘린다.\r\n",
        "                                                                      #Embedding 층은  크기가 (sampels, sequence_length, embedding_dimentionality)인 3D 실수형 텐서를 반환한다.\r\n",
        "                                                                      # 이런 3D텐서는 RNN층이나 1D합성곱 층에서 처리된다.\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(5000, activation = 'relu'))\r\n",
        "model.add(Dense(1000, activation = 'relu'))\r\n",
        "model.add(Dense(200, activation = 'relu'))\r\n",
        "model.add(Dense(64, activation = 'relu'))\r\n",
        "model.add(Dense(5, activation = 'softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 300)          32220600  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5000)              150005000 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1000)              5001000   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 200)               200200    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                12864     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 187,439,989\n",
            "Trainable params: 187,439,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxAqT1QCFw9O"
      },
      "source": [
        "# pretrainned embedding 사용시 주의점\r\n",
        "\r\n",
        "**Embedding을 로드 한 후 동결한다.** 훈련하는 동안 pre-trainned된 부분이 업데이트 된다면 이미 알고 있던 정보를 모두 잃게 됨.랜덤하게 초기화된 층에서 대량의 그래디언트 업데이트가 발생하면 이미 학습된 특성을 오염시키기 때문\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6fbHnEyGAsm"
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\r\n",
        "model.layers[0].trainable = False  # Embedding을 로드 한 후 동결한다. 훈련하는 동안 pre-trainned된 부분이 업데이트 된다면 이미 알고 있던 정보를 모두 잃게 됨.\r\n",
        "                                   # 랜덤하게 초기화된 층에서 대량의 그래디언트 업데이트가 발생하면 이미 학습된 특성을 오염시키기 때문\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvWoPc16S9-G"
      },
      "source": [
        "#Train model & evaluate\r\n",
        "\r\n",
        "맨처음에 model이 실행이 안되서 고생좀 했는데 .맨 처음에 데이터 토큰화 부분에서 max_words = 10000으로 (가장 빈도수가 높은 10000개의 단어만 사용) 설정해놔서 train_data중에 10000개 안에 못드는 단어를 찾으면 바로 트레이닝이 중지됨.\r\n",
        "그래서 max_words를 300차원 임베딩 공간에 있는 107402개를 모두 사용했음. 근데 토큰화 한걸 보면 42330개의 토큰 밖에 없는 걸 보면 굉장히 비효율 적인것을 알수 있음.\r\n",
        "다른 방법이 필요할듯?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qokQr95TSx8m",
        "outputId": "0e3c8743-c299-43b0-9f49-6dff51e45e40"
      },
      "source": [
        "model.compile(optimizer='Adam',\r\n",
        "              loss = 'CategoricalCrossentropy',\r\n",
        "              metrics = ['accuracy'])\r\n",
        "history = model.fit (X_train, y_train, validation_split=0.2, epochs = 10, batch_size = 8, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4O8Qs3YTUK0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
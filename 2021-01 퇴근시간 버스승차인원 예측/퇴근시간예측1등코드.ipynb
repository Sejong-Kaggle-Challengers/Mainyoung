{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "퇴근시간예측1등코드.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIe9bREgTWrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8ad5ae-4204-4a57-9ea5-6169053271b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxyoMmWkTsdi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqRDfAk_TS6_"
      },
      "source": [
        "# Library 예시\r\n",
        "import os\r\n",
        "\r\n",
        "# handling\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import datetime\r\n",
        "import random\r\n",
        "import gc\r\n",
        "from tqdm import tqdm_notebook as tqdm\r\n",
        "\r\n",
        "# visualization\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# prevent overfit\r\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.cluster import DBSCAN\r\n",
        "\r\n",
        "# model\r\n",
        "from sklearn.neural_network import MLPRegressor\r\n",
        "import xgboost as xgb\r\n",
        "import lightgbm as lgb\r\n",
        "\r\n",
        "SEED=42\r\n",
        "def seed_everything(seed=SEED):\r\n",
        "    random.seed(seed)\r\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "\r\n",
        "def rmse(y_true, y_pred):\r\n",
        "    return np.round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\r\n",
        "\r\n",
        "# ########################### BASIC SETTING\r\n",
        "# retval = os.getcwd() #사용자가 불러온거 처리하기 위해서 임시로만 생성한 것\r\n",
        "# os.chdir(retval+'\\\\data')\r\n",
        "# seed_everything(SEED)\r\n",
        "TARGET = '18~20_ride'\r\n",
        "\r\n",
        "########################### DATA LOAD\r\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/캐글스터디/퇴근 예측/train.csv')\r\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/캐글스터디/퇴근 예측/test.csv')\r\n",
        "sub = pd.read_csv('/content/drive/MyDrive/캐글스터디/퇴근 예측/submission_sample.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "pSGRIKGfVqnw",
        "outputId": "55e2bdd7-f522-4045-deb6-685a54e15fde"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>bus_route_id</th>\n",
              "      <th>in_out</th>\n",
              "      <th>station_code</th>\n",
              "      <th>station_name</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>6~7_ride</th>\n",
              "      <th>7~8_ride</th>\n",
              "      <th>8~9_ride</th>\n",
              "      <th>9~10_ride</th>\n",
              "      <th>10~11_ride</th>\n",
              "      <th>11~12_ride</th>\n",
              "      <th>6~7_takeoff</th>\n",
              "      <th>7~8_takeoff</th>\n",
              "      <th>8~9_takeoff</th>\n",
              "      <th>9~10_takeoff</th>\n",
              "      <th>10~11_takeoff</th>\n",
              "      <th>11~12_takeoff</th>\n",
              "      <th>18~20_ride</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>4270000</td>\n",
              "      <td>시외</td>\n",
              "      <td>344</td>\n",
              "      <td>제주썬호텔</td>\n",
              "      <td>33.48990</td>\n",
              "      <td>126.49373</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>4270000</td>\n",
              "      <td>시외</td>\n",
              "      <td>357</td>\n",
              "      <td>한라병원</td>\n",
              "      <td>33.48944</td>\n",
              "      <td>126.48508</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>4270000</td>\n",
              "      <td>시외</td>\n",
              "      <td>432</td>\n",
              "      <td>정존마을</td>\n",
              "      <td>33.48181</td>\n",
              "      <td>126.47352</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>4270000</td>\n",
              "      <td>시내</td>\n",
              "      <td>1579</td>\n",
              "      <td>제주국제공항(600번)</td>\n",
              "      <td>33.50577</td>\n",
              "      <td>126.49252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2019-09-01</td>\n",
              "      <td>4270000</td>\n",
              "      <td>시내</td>\n",
              "      <td>1646</td>\n",
              "      <td>중문관광단지입구</td>\n",
              "      <td>33.25579</td>\n",
              "      <td>126.41260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415418</th>\n",
              "      <td>415418</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>32820000</td>\n",
              "      <td>시내</td>\n",
              "      <td>1129</td>\n",
              "      <td>한림환승정류장(한림리)</td>\n",
              "      <td>33.41437</td>\n",
              "      <td>126.26336</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415419</th>\n",
              "      <td>415419</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>32820000</td>\n",
              "      <td>시내</td>\n",
              "      <td>1564</td>\n",
              "      <td>제주시외버스터미널</td>\n",
              "      <td>33.49946</td>\n",
              "      <td>126.51479</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415420</th>\n",
              "      <td>415420</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>32820000</td>\n",
              "      <td>시내</td>\n",
              "      <td>2322</td>\n",
              "      <td>해병부대</td>\n",
              "      <td>33.23100</td>\n",
              "      <td>126.26273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415421</th>\n",
              "      <td>415421</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>32820000</td>\n",
              "      <td>시내</td>\n",
              "      <td>3291</td>\n",
              "      <td>애월환승정류장(애월리)</td>\n",
              "      <td>33.46483</td>\n",
              "      <td>126.31870</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415422</th>\n",
              "      <td>415422</td>\n",
              "      <td>2019-09-30</td>\n",
              "      <td>32820000</td>\n",
              "      <td>시내</td>\n",
              "      <td>6115100</td>\n",
              "      <td>서귀포시외버스터미널</td>\n",
              "      <td>33.24873</td>\n",
              "      <td>126.50799</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>415423 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id        date  ...  11~12_takeoff 18~20_ride\n",
              "0            0  2019-09-01  ...            0.0        0.0\n",
              "1            1  2019-09-01  ...            0.0        5.0\n",
              "2            2  2019-09-01  ...            0.0        2.0\n",
              "3            3  2019-09-01  ...            0.0       53.0\n",
              "4            4  2019-09-01  ...            0.0        0.0\n",
              "...        ...         ...  ...            ...        ...\n",
              "415418  415418  2019-09-30  ...            0.0        0.0\n",
              "415419  415419  2019-09-30  ...            0.0        0.0\n",
              "415420  415420  2019-09-30  ...            0.0        0.0\n",
              "415421  415421  2019-09-30  ...            0.0        0.0\n",
              "415422  415422  2019-09-30  ...            0.0        0.0\n",
              "\n",
              "[415423 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxXQ-WFsV-rO",
        "outputId": "afef2158-7003-4fb2-9350-1fccc4920230"
      },
      "source": [
        "test_df['station_name']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 제주썬호텔\n",
              "1                  한라병원\n",
              "2                  정존마을\n",
              "3          제주국제공항(600번)\n",
              "4                  롯데호텔\n",
              "              ...      \n",
              "228165    고산환승정류장(고산1리)\n",
              "228166           애월고등학교\n",
              "228167     한림환승정류장(한림리)\n",
              "228168        제주시외버스터미널\n",
              "228169       서귀포시외버스터미널\n",
              "Name: station_name, Length: 228170, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-Mz9sDqcCpq",
        "outputId": "cb7fba1a-fb53-42ac-bfe9-53b5589b0f8f"
      },
      "source": [
        "train_df['station_name'] = train_df['station_name'].apply(lambda x: x.replace(' ', ''))\r\n",
        "test_df['station_name'] = test_df['station_name'].apply(lambda x: x.replace(' ', ''))\r\n",
        "pd.concat([train_df['station_name'], test_df['station_name']])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 제주썬호텔\n",
              "1                  한라병원\n",
              "2                  정존마을\n",
              "3          제주국제공항(600번)\n",
              "4              중문관광단지입구\n",
              "              ...      \n",
              "228165    고산환승정류장(고산1리)\n",
              "228166           애월고등학교\n",
              "228167     한림환승정류장(한림리)\n",
              "228168        제주시외버스터미널\n",
              "228169       서귀포시외버스터미널\n",
              "Name: station_name, Length: 643593, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLFI402IT_v7"
      },
      "source": [
        "# dataframe copy? (tr=train, te=test)\r\n",
        "def df_copy(tr_df, te_df):\r\n",
        "    tr = tr_df.copy();te = te_df.copy()\r\n",
        "    return tr, te\r\n",
        "\r\n",
        "# 앞에서 정의 했던 df_copy를 사용하여 tr, te를 불러옴\r\n",
        "def base_preprocessing(tr_df, te_df):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "#bus_route_id column의 데이터 -> 뒷 4자리 0을 제외함, 모든 열의 데이터 타입을 int로 변경\r\n",
        "    tr['bus_route_id'] = tr['bus_route_id'].apply(lambda x: str(x)[:-4]).astype(int)\r\n",
        "    te['bus_route_id'] = te['bus_route_id'].apply(lambda x: str(x)[:-4]).astype(int)\r\n",
        "#station_name을 앞 두글자만 받음\r\n",
        "    tr['station_name2'] = tr['station_name'].apply(lambda x: str(x)[:2])\r\n",
        "    te['station_name2'] = te['station_name'].apply(lambda x: str(x)[:2])\r\n",
        "# station_name안에 있는 띄어쓰기 삭제 (?? 왜하는거지?)\r\n",
        "    tr['station_name'] = tr['station_name'].apply(lambda x: x.replace(' ', ''))\r\n",
        "    te['station_name'] = te['station_name'].apply(lambda x: x.replace(' ', ''))\r\n",
        "# LabelEncoder를 활용하여 변환함 ,(concat은 왜 함? 1열로 만듬)\r\n",
        "    le = LabelEncoder().fit(pd.concat([tr['station_name'], te['station_name']]))\r\n",
        "    le2 = LabelEncoder().fit(pd.concat([tr['station_name2'], te['station_name2']]))\r\n",
        "# date column을 day, week, weekday로 슬라이싱 (pd.to_datetime에서는 많은 함수를 제공하고 있음.)\r\n",
        "# to_datetime의 메뉴얼 ('https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html')\r\n",
        "# 참고 ('https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221603462366&proxyReferer=https:%2F%2Fwww.google.com%2F')\r\n",
        "    for df in [tr, te]:\r\n",
        "        df['day'] = pd.to_datetime(df['date']).dt.day\r\n",
        "        df['week'] = pd.to_datetime(df['date']).dt.week\r\n",
        "        df['weekday'] = pd.to_datetime(df['date']).dt.weekday\r\n",
        "\r\n",
        "#transform 해서 집어넣음\r\n",
        "        df['station_name'] = le.transform(df['station_name'])\r\n",
        "        df['station_name2'] = le2.transform(df['station_name2'])\r\n",
        "\r\n",
        "# 탑승/하차 인원을 합침\r\n",
        "        df['6~8_ride'] = df[['6~7_ride','7~8_ride']].sum(1)\r\n",
        "        df['6~9_ride'] = df[['6~7_ride','7~8_ride','8~9_ride']].sum(1)\r\n",
        "        df['6~10_ride'] = df[['6~7_ride','7~8_ride','8~9_ride', '9~10_ride']].sum(1)\r\n",
        "        df['6~8_takeoff'] = df[['6~7_takeoff','7~8_takeoff']].sum(1)\r\n",
        "        df['6~9_takeoff'] = df[['6~7_takeoff','7~8_takeoff','8~9_takeoff']].sum(1)\r\n",
        "        df['6~10_takeoff'] = df[['6~7_takeoff','7~8_takeoff','8~9_takeoff', '9~10_takeoff']].sum(1)\r\n",
        "    te['day'] = te['day']+30\r\n",
        "    return tr, te\r\n",
        "#위도와 경도를 합친 후 LabelEncoder로 변환\r\n",
        "def lat_long_create(tr_df, te_df):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    tr['lat_long'] = np.round(tr['latitude'], 2).astype(str) + np.round(tr['longitude'], 2).astype(str)\r\n",
        "    te['lat_long'] = np.round(te['latitude'], 2).astype(str) + np.round(te['longitude'], 2).astype(str)\r\n",
        "    le = LabelEncoder().fit(pd.concat([tr['lat_long'], te['lat_long']]))\r\n",
        "    tr['station_lat_long'] = le.transform(tr['lat_long'])\r\n",
        "    te['station_lat_long'] = le.transform(te['lat_long'])\r\n",
        "\r\n",
        "    tr['lat_long'] = np.round(tr['latitude'], 3).astype(str) + np.round(tr['longitude'], 2).astype(str)\r\n",
        "    te['lat_long'] = np.round(te['latitude'], 3).astype(str) + np.round(te['longitude'], 2).astype(str)\r\n",
        "    le = LabelEncoder().fit(pd.concat([tr['lat_long'], te['lat_long']]))\r\n",
        "    tr['station_lat_long2'] = le.transform(tr['lat_long'])\r\n",
        "    te['station_lat_long2'] = le.transform(te['lat_long'])\r\n",
        "    return tr, te\r\n",
        "#bus_route_id와 station_code를 합침/bus_route_id와 station_lat_long를 합침\r\n",
        "def feature_combine(tr_df, te_df):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    for df in [tr, te]:\r\n",
        "        df['bus_route_id_station_code'] = ((df['bus_route_id']).astype(str) + (df['station_code']).astype(str)).astype('category')\r\n",
        "        df['bus_route_id_station_lat_long'] = ((df['bus_route_id']).astype(str) + (df['station_lat_long']).astype(str)).astype('category')\r\n",
        "    return tr, te\r\n",
        "#카테고리형으로 변환시킴\r\n",
        "def category_transform(tr_df, te_df, columns):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    for df in [tr, te]:\r\n",
        "        df[columns] = df[columns].astype(str).astype('category')\r\n",
        "    return tr, te\r\n",
        "#?!!?!?!\r\n",
        "def frequency_encoding(tr_df, te_df, columns, normalize=False):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    for col in columns:\r\n",
        "        if not normalize:\r\n",
        "            freq_encode = pd.concat([tr[col], te[col]]).value_counts()\r\n",
        "            tr[col+'_fq_enc'] = tr[col].map(freq_encode)\r\n",
        "            te[col+'_fq_enc'] = te[col].map(freq_encode)\r\n",
        "        else:\r\n",
        "            freq_encode = pd.concat([tr[col], te[col]]).value_counts(normalize=True)\r\n",
        "            tr[col+'_fq_enc_nor'] = tr[col].map(freq_encode)\r\n",
        "            te[col+'_fq_enc_nor'] = te[col].map(freq_encode)\r\n",
        "    return tr, te\r\n",
        "\r\n",
        "#np.where은 인덱스를 반환, isin은 열이 list의 값들을 포함하는 모든 행들을 골라내고 이진값을 반환함\r\n",
        "def remove_outlier(tr_df, te_df, columns):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    for col in columns:\r\n",
        "        tr[col] = np.where(tr[col].isin(te[col]), tr[col], 0)\r\n",
        "        te[col] = np.where(te[col].isin(tr[col]), te[col], 0)\r\n",
        "    return tr, te\r\n",
        "# groupby agg 함수 ('https://rfriend.tistory.com/392') 슬라이싱 기법의 한 종류인듯?!\r\n",
        "def day_agg(tr_df, te_df, merge_columns, columns, aggs=['mean']):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    for merge_column in merge_columns:\r\n",
        "        for col in columns:\r\n",
        "            for agg in aggs:\r\n",
        "                valid = pd.concat([tr[[merge_column, col]], te[[merge_column, col]]])\r\n",
        "                new_cn = merge_column + '_' + agg + '_' + col\r\n",
        "                if agg=='quantile':\r\n",
        "                    valid = valid.groupby(merge_column)[col].quantile(0.8).reset_index().rename(columns={col:new_cn})\r\n",
        "                else:\r\n",
        "                    valid = valid.groupby(merge_column)[col].agg([agg]).reset_index().rename(columns={agg:new_cn})\r\n",
        "                valid.index = valid[merge_column].tolist()\r\n",
        "                valid = valid[new_cn].to_dict()\r\n",
        "            \r\n",
        "                tr[new_cn] = tr[merge_column].map(valid)\r\n",
        "                te[new_cn] = te[merge_column].map(valid)\r\n",
        "    return tr, te\r\n",
        "\r\n",
        "def sub_day_agg(tr_df, te_df, merge_columns, date_columns, columns, aggs=['mean']):\r\n",
        "    tr, te = df_copy(tr_df, te_df)\r\n",
        "    for merge_column in merge_columns:\r\n",
        "        for date in date_columns:\r\n",
        "            tr['mc_date'] = tr[merge_column].astype(str) + '_' +tr[date].astype(str)\r\n",
        "            te['mc_date'] = te[merge_column].astype(str) + '_' +te[date].astype(str)\r\n",
        "            for col in columns:\r\n",
        "                for agg in aggs:\r\n",
        "                    valid = pd.concat([tr[['mc_date', col]], te[['mc_date', col]]])\r\n",
        "                    new_cn = merge_column + '_' + date + '_' + col + '_' + agg\r\n",
        "                    if agg=='quantile':\r\n",
        "                        valid = valid.groupby('mc_date')[col].quantile(0.8).reset_index().rename(columns={col:new_cn})\r\n",
        "                    else:\r\n",
        "                        valid = valid.groupby('mc_date')[col].agg([agg]).reset_index().rename(columns={agg:new_cn})\r\n",
        "                    valid.index = valid['mc_date'].tolist()\r\n",
        "                    valid = valid[new_cn].to_dict()\r\n",
        "                \r\n",
        "                    tr[new_cn] = tr['mc_date'].map(valid)\r\n",
        "                    te[new_cn] = te['mc_date'].map(valid)\r\n",
        "    tr = tr.drop(columns=['mc_date'])\r\n",
        "    te = te.drop(columns=['mc_date'])\r\n",
        "    return tr, te"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E3woAh0UWoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa0f9d4-024c-401f-eb62-b3247b7e1778"
      },
      "source": [
        "########################### Final features list\r\n",
        "remove_features = ['id', 'date', 'in_out', TARGET]\r\n",
        "ride_take = ['6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride', '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff']\r\n",
        "\r\n",
        "remove_features += ['day', 'week', 'weekday', 'lat_long']\r\n",
        "tr, te = base_preprocessing(train_df, test_df)\r\n",
        "tr, te = lat_long_create(tr, te)\r\n",
        "tr, te = feature_combine(tr, te)\r\n",
        "\r\n",
        "ride_take += ['6~8_ride', '6~9_ride', '6~10_ride', '6~8_takeoff', '6~9_takeoff', '6~10_takeoff']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNeM4qO1UkEp"
      },
      "source": [
        "tr, te = day_agg(tr, te, merge_columns=['day'], columns=ride_take, aggs=['mean'])\r\n",
        "tr, te = sub_day_agg(tr, te, merge_columns=['bus_route_id', 'station_code', 'station_lat_long'], date_columns=['day'], columns=ride_take, aggs=['mean'])\r\n",
        "tr, te = sub_day_agg(tr, te, merge_columns=['bus_route_id', 'station_code', 'station_name', 'station_lat_long'], date_columns=['day'], columns=ride_take, aggs=['quantile'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj2lR5O_UxEy"
      },
      "source": [
        "category_features = ['bus_route_id', 'station_code', 'station_name', 'station_name2', 'station_lat_long', 'station_lat_long2', 'bus_route_id_station_code', 'bus_route_id_station_lat_long']\r\n",
        "tr, te = frequency_encoding(tr, te, category_features)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylyNMWAwUzud"
      },
      "source": [
        "os.chdir(retval)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "tIvV6tTjXF0L",
        "outputId": "2dfa5a86-e3c0-4f64-f0bb-8ed17418a1ac"
      },
      "source": [
        "########################### Model\r\n",
        "def make_predictions(model, tr_df, tt_df, features_columns, target, params, category_feature=[''], NFOLDS=4, oof_save=False, clip=999, SEED=SEED):\r\n",
        "    X,y = tr_df[features_columns], tr_df[target]\r\n",
        "    kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\r\n",
        "\r\n",
        "    oof = np.zeros(len(tr_df))\r\n",
        "    pred = np.zeros(len(tt_df))\r\n",
        "    fi_df = pd.DataFrame()\r\n",
        "    \r\n",
        "    for fold_, (trn_idx, val_idx) in enumerate(kf.split(X)):\r\n",
        "        print('Fold:',fold_)\r\n",
        "        tr_data = lgb.Dataset(X.loc[trn_idx], label=y[trn_idx].clip(0, clip))\r\n",
        "        vl_data = lgb.Dataset(X.loc[val_idx], label=y[val_idx])\r\n",
        "        if model=='lgb':\r\n",
        "            estimator = lgb.train(params, tr_data, valid_sets = [tr_data, vl_data], verbose_eval = 500)\r\n",
        "            fi_df = pd.concat([fi_df, pd.DataFrame(sorted(zip(estimator.feature_importance(), features_columns)), columns=['Value', 'Feature'])])\r\n",
        "        \r\n",
        "        oof[val_idx] = estimator.predict(X.loc[val_idx])\r\n",
        "        pred += estimator.predict(tt_df[features_columns])/NFOLDS\r\n",
        "        del estimator\r\n",
        "        gc.collect()\r\n",
        "\r\n",
        "    oof = np.where(oof&gt;0, oof, 0) #?!?!?!?!?!?!?!!?!?\r\n",
        "    pred = np.where(pred&gt;0, pred, 0)\r\n",
        "\r\n",
        "    if oof_save:\r\n",
        "        if model=='lgb':\r\n",
        "            np.save(retval+'\\\\content\\\\oof_lgb.npy', oof)\r\n",
        "            np.save(retval+'\\\\content\\\\pred_lgb.npy', pred)\r\n",
        "        elif model=='cat':\r\n",
        "            np.save(retval+'\\\\content\\\\oof_cat.npy', oof)\r\n",
        "            np.save(retval+'\\\\content\\\\pred_cat.npy', pred)\r\n",
        "\r\n",
        "    tt_df[target] = pred\r\n",
        "    print('OOF RMSE:', rmse(y, oof))\r\n",
        "    \r\n",
        "    try:\r\n",
        "        fi_df = fi_df.groupby('Feature').mean().reset_index().sort_values('Value')\r\n",
        "    except:\r\n",
        "        pass\r\n",
        "\r\n",
        "    return tt_df[['id', target]], fi_df\r\n",
        "## -------------------"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-c93df3f3389e>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    oof = np.where(oof&gt;0, oof, 0)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "4JkUxIJrZQw1",
        "outputId": "97126b17-e1e3-46ba-cf18-16000893b4b0"
      },
      "source": [
        "########################### Model\r\n",
        "def make_predictions(model, tr_df, tt_df, features_columns, target, params, category_feature=[''], NFOLDS=4, oof_save=False, clip=999, SEED=SEED):\r\n",
        "    X,y = tr_df[features_columns], tr_df[target]\r\n",
        "    kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\r\n",
        "\r\n",
        "    oof = np.zeros(len(tr_df))\r\n",
        "    pred = np.zeros(len(tt_df))\r\n",
        "    fi_df = pd.DataFrame()\r\n",
        "    \r\n",
        "    for fold_, (trn_idx, val_idx) in enumerate(kf.split(X)):\r\n",
        "        print('Fold:',fold_)\r\n",
        "        tr_data = lgb.Dataset(X.loc[trn_idx], label=y[trn_idx].clip(0, clip))\r\n",
        "        vl_data = lgb.Dataset(X.loc[val_idx], label=y[val_idx])\r\n",
        "        if model=='lgb':\r\n",
        "            estimator = lgb.train(params, tr_data, valid_sets = [tr_data, vl_data], verbose_eval = 500)\r\n",
        "            fi_df = pd.concat([fi_df, pd.DataFrame(sorted(zip(estimator.feature_importance(), features_columns)), columns=['Value', 'Feature'])])\r\n",
        "        \r\n",
        "        oof[val_idx] = estimator.predict(X.loc[val_idx])\r\n",
        "        pred += estimator.predict(tt_df[features_columns])/NFOLDS\r\n",
        "        del estimator\r\n",
        "        gc.collect()\r\n",
        "\r\n",
        "    oof = np.where(oof&gt;0, oof, 0)\r\n",
        "    pred = np.where(pred&gt;0, pred, 0)\r\n",
        "\r\n",
        "    if oof_save:\r\n",
        "        if model=='lgb':\r\n",
        "            np.save(retval+'\\\\content\\\\oof_lgb.npy', oof)\r\n",
        "            np.save(retval+'\\\\content\\\\pred_lgb.npy', pred)\r\n",
        "        elif model=='cat':\r\n",
        "            np.save(retval+'\\\\content\\\\oof_cat.npy', oof)\r\n",
        "            np.save(retval+'\\\\content\\\\pred_cat.npy', pred)\r\n",
        "\r\n",
        "    tt_df[target] = pred\r\n",
        "    print('OOF RMSE:', rmse(y, oof))\r\n",
        "    \r\n",
        "    try:\r\n",
        "        fi_df = fi_df.groupby('Feature').mean().reset_index().sort_values('Value')\r\n",
        "    except:\r\n",
        "        pass\r\n",
        "\r\n",
        "    return tt_df[['id', target]], fi_df\r\n",
        "## -------------------"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-c93df3f3389e>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    oof = np.where(oof&gt;0, oof, 0)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcEgo7eoXY0U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}